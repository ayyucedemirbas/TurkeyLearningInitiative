{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The summary of what we have done in week 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The DataFrame is conceptually a two-dimensional series object, where there's an index and multiple columns of  content, with each column having a label. \n",
    "- In fact, the distinction between a column and a row is really only a  conceptual distinction. \n",
    "- you can think of the DataFrame itself as simply a two-axes labeled array.\n",
    "- It's just like excel table in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Dataframe from dictionaries and series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by importing our pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe - 1\n",
    "#### Series becomes the columns of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "author = ['Mehmet', 'Ali', 'Ayberk', 'Batuhan']\n",
    "article = [210, 211, 114, 178]\n",
    "  \n",
    "auth_series    = pd.Series(author)\n",
    "article_series = pd.Series(article)\n",
    "article_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d1 = { 'Author': auth_series, 'Article': article_series }\n",
    "#this is a dictionary\n",
    "#convert the dictionary to a dataframe\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(d1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to add series externally in dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age = [17, 21, 24,32]\n",
    "\n",
    "result['Age'] = pd.Series(age)\n",
    "\n",
    "result\n",
    "#We have added one more series externally named as age of the authors, \n",
    "# then directly added this series in the pandas dataframe. \n",
    "# Remember one thing if any value is missing then by default \n",
    "# it will be converted into NaN value i.e null by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "town = [\"Ist\", \"Ank\", \"Trb\"]\n",
    "  \n",
    "result['Town'] = pd.Series(town)\n",
    "  \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "result.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe - 2\n",
    "\n",
    "#### Series becomes the rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create three school records for students and their  class grades.\n",
    "# I'll create each as a series which has a student name, the class name, and the score. \n",
    "record1 = pd.Series({    'Name': 'Alice',\n",
    "                        'Class': 'Physics',\n",
    "                        'Score': 85})\n",
    "\n",
    "record2 = pd.Series({    'Name': 'Jack',\n",
    "                        'Class': 'Chemistry',\n",
    "                        'Score': 82})\n",
    "\n",
    "record3 = pd.Series({   'Name': 'Helen',\n",
    "                        'Class': 'Biology',\n",
    "                        'Score': 90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record1['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like a Series, the DataFrame object is index. Here I'll use a group of series, where each series \n",
    "# represents a row of data. Just like the Series function, we can pass in our individual items\n",
    "# in an array, and we can pass in our index values as a second arguments\n",
    "df = pd.DataFrame([record1, record2, record3], index=['school1', 'school2', 'school1'])\n",
    "\n",
    "# And just like the Series we can use the head() function to see the first several rows of the\n",
    "# dataframe, including indices from both axes, and we can use this to verify the columns and the rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative method is that you could use --a list of dictionaries--, \n",
    "# where each dictionary represents a row of data.\n",
    "\n",
    "students = [{'Name': 'Alice',\n",
    "              'Class': 'Physics',\n",
    "              'Score': 85},\n",
    "            {'Name': 'Jack',\n",
    "             'Class': 'Chemistry',\n",
    "             'Score': 82},\n",
    "            {'Name': 'Helen',\n",
    "             'Class': 'Biology',\n",
    "             'Score': 90}]\n",
    "#df = pd.DataFrame([record1, record2, record3],\n",
    "#                  index=['school1', 'school2', 'school1'])\n",
    "\n",
    "df = pd.DataFrame(students, index=['school1', 'school2', 'school1'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] # you can read columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['school2'] # you canNOT read rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school2']\n",
    "#df.iloc =>integer location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# School1 has multiple rows. \n",
    "# Lets query for school1 records\n",
    "df.loc['school1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use transpose\n",
    "df.T # transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T['school1'] # recall that df['school1'] is not possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can call .loc on the transpose to get the student names only\n",
    "df.T['Name'] # we will have an error for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.loc['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1'] #=> this is a dataframe itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc['school1']['Name'] # called chaining. Returns a copy!!!\n",
    "# If you are #CHANGING# data, though this is an important distinction \n",
    "# and can be a source of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1','Name'] \n",
    "# remember we also did the same thing before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school2']['Name'] = 'mehmet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school2','Name'] = 'mehmet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1'] = \"a\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SLICING\n",
    "If you need more than one columns...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example, where we ask for all the names and scores for all schools using the \n",
    "# .loc operator.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1',['Name', 'Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[: , ['Name', 'Score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"school1\", :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop('Name', inplace=True, axis=1) #gives a copy of df with the given rows removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But if we look at our original DataFrame we see the data is still intact.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop has two interesting optional parameters. \n",
    "# 1) inplace\n",
    "# if it's set to true, the DataFrame will be updated in place, instead of a copy being returned. \n",
    "# 2) axis \n",
    "# The second parameter is the axes, which should be dropped. \n",
    "# 0, ==> Row,    1 ==> column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, lets make a copy of a DataFrame using .copy()\n",
    "copy_df  = df.copy()\n",
    "copy_df2 = df\n",
    "copy_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why did we do this and use a copy function instead of creating a copy with copy_df = df.copy()\n",
    "\n",
    "#later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets drop the name column in this copy\n",
    "copy_df.drop(\"school2\", inplace=True, axis=0)\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, adding a new column to the DataFrame is as easy as assigning it to some value using\n",
    "# the indexing operator. For instance, if we wanted to add a class ranking column with default \n",
    "# value of None, we could do so by using the assignment operator after the square brackets.\n",
    "# This broadcasts the default value to the new column immediately.\n",
    "\n",
    "df['ClassRanking'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this lecture you've learned about the data structure you'll use the most in pandas, the DataFrame. The \n",
    "dataframe is indexed both by row and column, and you can easily select individual rows and project the columns \n",
    "you're interested in using the familiar indexing methods from the Series class. You'll be gaining a lot of \n",
    "experience with the DataFrame in the content to come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ClassRanking'] = [22,21,20]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1', \"Score\"] =23\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALIASING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember aliasing in Lists. \n",
    "L1 = [1,2,'a']\n",
    "L2 = L1\n",
    "L3 = L1[:]\n",
    "L2[0] = \"mehmet\"\n",
    "L3[1] = \"dataframe\"\n",
    "print(L1,L2, L3)\n",
    "#L2 and L1 are different names of the SAME list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df # df2 becomes the new name of the existing dataframe df. \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc['school2'] = 1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATAFRAME: INDEXING AND LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pandas mades it easy to turn a CSV into a dataframe, we just call read_csv()\n",
    "df = pd.read_csv('datasets/Admission_Predict.csv',delimiter=\",\", index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Chance of Admit '])\n",
    "#or\n",
    "#X = df[['gre score', 'toefl score', 'university rating', 'sop', 'lor', 'cgpa','research']]\n",
    "y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see strip() and lower()\n",
    "print('  Ahmet  '.strip())\n",
    "print('  Ahmet  '.lower())\n",
    "\n",
    "print('AhMeT '.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " [x.lower().strip() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for better representation \n",
    "df.columns = [x.lower().strip() for x in df.columns]\n",
    "# And we'll take a look at the results\n",
    "df.head(5)\n",
    "\n",
    "# And let's look at the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admit_mask = df['chance of admit'] > 0.7 # we can use this masking to pick the students\n",
    "#whose chance of admit is larger than 0.7\n",
    "admit_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df['chance of admit'] > 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df['chance of admit'] > 0.7).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shorthand way of writing above is\n",
    "df[ df['chance of admit'] > 0.7 ]  #it generates a copy of dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['chance of admit'] > 0.7) & (df['chance of admit'] < 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chance of admit'].gt(0.7) & df['chance of admit'].lt(0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ignore this for now. df['chance of admit'].gt(0.7).lt(0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.5 is over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also try this to make selections \n",
    "df[\"gre score\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or this one. \n",
    "df[[\"gre score\",\"toefl score\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Indexing - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/Admission_Predict.csv\", index_col=0, delimiter=\",\")\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SOP'] = df.index\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Serial No.'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('SOP',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another data file ==> MPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/mpg - original.csv',index_col=0,delimiter=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manufacturer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manufacturer'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[19]['manufacturer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manufacturer'] == \"audi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = df[ df['manufacturer'] == \"audi\" ]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['manufacturer', 'model'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"audi\", \"a4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"audi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the NaN value sin dataframes\n",
    "\n",
    "df.fillna(0, inplace=True)# if inplace is True, the original df is modified. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applying functions to dataframes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([[9, 16], [4,25], [100,64]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sqrt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sum, axis=0) #axis = 0 means sum the elements in a column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sum, axis=1)#axis = 1 means sum the elements in a row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture we're going to address how you can bring multiple dataframe objects together, either by\n",
    "merging them horizontally, or by concatenating them vertically. Before we jump into the code, we need to\n",
    "address a little relational theory and to get some language conventions down. I'm going to bring in an image\n",
    "to help explain some concepts.\n",
    "\n",
    "![Venn Diagram](merging1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is a Venn Diagram. A Venn Diagram is traditionally used to show set membership. For example, the \n",
    "circle on the left is the population of students at a university. The circle on the right is the population\n",
    "of  staff at a university. And the overlapping region in the middle are all of those students who are also\n",
    "staff.  Maybe these students run tutorials for a course, or grade assignments, or engage in running research\n",
    " experiments.\n",
    "\n",
    "So, this diagram shows two populations whom we might have data about, but there is overlap between those \n",
    "populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to translating this to pandas, we can think of the case where we might have these two \n",
    "populations as indices in separate DataFrames, maybe with the label of Person Name. When we want to join the\n",
    "DataFrames together, we have some choices to make. First what if we want a list of all the people regardless\n",
    "of whether they're staff or student, and all of the information we can get on them? In database terminology,\n",
    "this is called a full outer join. And in set theory, it's called a union. In the Venn diagram, it represents\n",
    "everyone in any circle.\n",
    "\n",
    "Here's an image of what that would look like in the Venn diagram.\n",
    "\n",
    "![Union](merging2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite possible though that we only want those people who we have maximum information for, those people\n",
    "who are both staff and students. Maybe being a staff member and a student involves getting a tuition waiver,\n",
    "and we want to calculate the cost of this. In database terminology, this is called an inner join. Or in set\n",
    "theory, the intersection. It is represented in the Venn diagram as the overlapping parts of each circle.\n",
    "\n",
    "Here's what that looks like: ![Intersection](merging3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging Dataframes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# First we create two DataFrames, staff and students.\n",
    "staff_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR'},\n",
    "                         {'Name': 'Sally', 'Role': 'Course liasion'},\n",
    "                         {'Name': 'James', 'Role': 'Grader'}])\n",
    "# And lets index these staff by name\n",
    "staff_df = staff_df.set_index('Name')\n",
    "# Now we'll create a student dataframe\n",
    "student_df = pd.DataFrame([{'Name': 'James', 'School': 'Business'},\n",
    "                           {'Name': 'Mike', 'School': 'Law'},\n",
    "                           {'Name': 'Sally', 'School': 'Engineering'}])\n",
    "# And we'll index this by name too\n",
    "student_df = student_df.set_index('Name')\n",
    "\n",
    "# And lets just print out the dataframes\n",
    "print(staff_df.head())\n",
    "print(student_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='outer', left_index=True, right_index=True) #Outer = union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='inner', left_index=True, right_index=True) #innter = intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='left', left_index=True, right_index=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='right', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('datasets/mpg.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupy - Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.groupby(\"manufacturer\").agg({\"cty\":np.average}) # 3 values and 2 nan values, it will be divided by 5.  \n",
    "df.groupby(\"manufacturer\").agg({\"cty\":np.nanmean}) #ignores NaN values=> diveded by 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby - Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cols=['manufacturer','cty','hwy','trans']\n",
    "cols=['brand','cty']\n",
    "\n",
    "df[cols]\n",
    "df[cols].groupby('brand').transform(np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols].groupby('manufacturer').transform(np.nanmean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby - Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('manufacturer').filter(lambda x: np.nanmean(x['cty'])>20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('brand').filter(lambda x: np.nanmean(x['cty'])>20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby - Applying\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"datasets/mpg.csv\")\n",
    "# And lets just include some of the columns we were interested in previously\n",
    "df=df[['manufacturer','cty']]\n",
    "df.head(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_cty(group):\n",
    "    # group is a dataframe just of whatever we have grouped by, e.g. manufacturer, \n",
    "    #hence we can treat this as the complete dataframe\n",
    "    avg=np.nanmean(group[\"cty\"])\n",
    "    #print('avg',avg)\n",
    "    # now broadcast our formula and create a new column\n",
    "    group[\"cty_diff\"]=np.abs(avg-group[\"cty\"])\n",
    "    return group\n",
    "calc_mean_cty(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIVOT TABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"datasets/mpg.csv\", index_col=0)\n",
    "df.pivot_table(values='cty', index='class', columns='cyl', aggfunc=[np.mean, np.max,np.min])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last but not the least...\n",
    "In fact the most important operation:\n",
    "\n",
    "# Reading - writing Excel Files !!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from excel files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataframe1 = pd.read_excel('Information.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1 = pd.read_excel('Information.xlsx', \"CourseInfo\")\n",
    "dataframe2 = pd.read_excel('Information.xlsx', \"Classrooms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3 = pd.read_excel('Information.xlsx', \"CourseInfo\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExcelFileHandler = pd.ExcelFile('Information.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExcelFileHandler.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExcelFileHandler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict  =  {}\n",
    "\n",
    "for i in ExcelFileHandler.sheet_names:\n",
    "    df_dict[i] = pd.read_excel('Information.xlsx', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPerations on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"CourseInfo\"]\n",
    "df_dict[\"Classrooms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"CourseInfo\"].set_index(\"Course\") ## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Howver there is no change in the dataframe\n",
    "df_dict[\"CourseInfo\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"CourseInfo\"].set_index(\"Course\")[\"CapacityofCourses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Capacity = df_dict[\"CourseInfo\"].set_index(\"Course\")[\"CapacityofCourses\"]\n",
    "Capacity[\"END1991_Gr1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"CourseInfo\"][df_dict[\"CourseInfo\"][\"Class\"] == \"ONE\" ][\"Course\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_dict[\"CourseInfo\"][\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to excel files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"CourseInfo\"].to_excel(\"CourseInfo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"CourseInfo\"].to_excel(\"CourseInfo.xlsx\", sheet_name=\"WritingSheetNames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"CourseInfo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more neat way to do this is following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"Rt.xlsx\", engine='xlsxwriter')\n",
    "df_dict[\"CourseInfo\"].to_excel(writer, sheet_name='Sheeta')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to write to multiple sheets? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'Data': ['a', 'b', 'c', 'd']})\n",
    "\n",
    "df2 = pd.DataFrame({'Data': [1, 2, 3, 4]})\n",
    "\n",
    "df3 = pd.DataFrame({'Data': [1.1, 1.2, 1.3, 1.4]})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('multiple.xlsx', engine='xlsxwriter')\n",
    "\n",
    "df1.to_excel(writer, sheet_name='Sheeta')\n",
    "\n",
    "df2.to_excel(writer, sheet_name='Sheetb')\n",
    "\n",
    "df3.to_excel(writer, sheet_name='Sheetc')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use it for our own case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "ExcelFileHandler.sheet_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"multiple_ourcase.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "\n",
    "for i in ExcelFileHandler.sheet_names:\n",
    "    df_dict[i].to_excel(writer, sheet_name=i)\n",
    "writer.save()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
